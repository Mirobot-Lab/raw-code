import pickle
import time
import numpy as np
from wlkata_mirobot import WlkataMirobot
from experiments.robot.libero.run_libero_eval import GenerateConfig
from experiments.robot.openvla_utils import (
    get_vla, get_processor, get_action_head,
    get_proprio_projector, get_vla_action
)
from prismatic.vla.constants import NUM_ACTIONS_CHUNK, PROPRIO_DIM

#run wlkata mirobot directly with just one frame 

# --- 1) Model configuration ---
cfg = GenerateConfig(
    pretrained_checkpoint="moojink/openvla-7b-oft-finetuned-libero-spatial",
    use_l1_regression=True,
    use_diffusion=False,
    use_film=False,
    num_images_in_input=2,
    use_proprio=True,
    load_in_8bit=False,
    load_in_4bit=False,
    center_crop=True,
    num_open_loop_steps=NUM_ACTIONS_CHUNK,
    unnorm_key="libero_spatial_no_noops",
)

# --- 2) Load model & components ---
vla = get_vla(cfg)
processor = get_processor(cfg)
action_head = get_action_head(cfg, llm_dim=vla.llm_dim)
proprio_projector = get_proprio_projector(
    cfg, llm_dim=vla.llm_dim, proprio_dim=PROPRIO_DIM
)

# --- 3) Load your observation ---
# Toggle between sample and your recorded data:
with open("mirobot_data.pkl", "rb") as f:
    # Your file should contain a single dict, not a list
    observation = pickle.load(f)

# If your dict uses "proprio" instead of "state", rename it:
if "proprio" in observation:
    observation["state"] = observation.pop("proprio")

# --- 4) Generate action chunk ---
actions = get_vla_action(
    cfg,
    vla,
    processor,
    observation,
    observation["task_description"],
    action_head,
    proprio_projector
)

print("Generated action chunk:")
for i, act in enumerate(actions, start=1):
    print(f"  Step {i}: {act}")

# --- 5) Initialize & home the robot ---
arm = WlkataMirobot()  # auto‐detect port
arm.home()
time.sleep(2)

# --- 6) Apply the very first action ---
delta = actions[0][:6]  # use first 6 dims
scale = np.array([0.01, 0.01, 0.01, 1, 1, 1], dtype=np.float32)
delta_scaled = delta * scale

# Read current pose
pose = arm.pose
current = np.array([
    pose.x, pose.y, pose.z,
    pose.roll, pose.pitch, pose.yaw
], dtype=np.float32)

# Compute & send target pose
target = current + delta_scaled
print(f"\nExecuting first action on Mirobot → target pose: {target}")
arm.set_tool_pose(*target, roll=target[3], pitch=target[4], yaw=target[5])


